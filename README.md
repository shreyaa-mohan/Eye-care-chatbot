# ğŸ‘ï¸â€ğŸ—¨ï¸ Eye-Care Chatbot

A conversational AI chatbot designed to assist users with eye-care-related queries. Built with LLaMA-2, Chainlit UI, and a custom ingestion pipeline to provide helpful, context-aware responses.

---

## ğŸ“ Project Structure

â”œâ”€â”€ chainlit/ # Chainlit configuration and UI flow  
â”œâ”€â”€ ingest.py # Script to load and process data  
â”œâ”€â”€ model.py # Code for loading LLaMA-2 and responding to prompts  
â”œâ”€â”€ requirements.txt # Python dependencies  
â”œâ”€â”€ README.md # Project documentation  
â””â”€â”€ .env # (Optional) Environment variables  


## ğŸš€ Features

- ğŸ¤– AI-powered chatbot using **LLaMA-2 7B Chat** model
- ğŸ§  Ingestion pipeline for custom domain knowledge
- ğŸŒ Lightweight **Chainlit-based UI**
- ğŸ”’ Secure use of `.env` for managing secrets or paths
- ğŸ“‚ Modular code (`ingest.py`, `model.py`)

---

## ğŸ”§ Installation

### 1. Clone the repository

- git clone https://github.com/shreyaa-mohan/Eye-care-chatbot.git
- cd Eye-care-chatbot
### 2. Set up a virtual environment (optional but recommended)

- python -m venv venv
- source venv/bin/activate     
### 3. Install dependencies

- pip install -r requirements.txt
### âš™ï¸ Setup
1. Add environment variables
- Create a .env file in the root directory:
- MODEL_PATH=path/to/llama-2-7b-chat.ggmlv3.q8_0.bin
  - Replace path/to/... with your actual model path.

### â–¶ï¸ Running the Chatbot
- Step 1: Ingest data  

 python ingest.py
- Step 2: Start the chatbot  

 chainlit run model.py -w
ğŸ“Œ Notes
- The LLaMA-2 .bin model is large and not included in the repo.

- This project is meant for educational or research use only.

ğŸ“ License
This project is licensed under the MIT License.

ğŸ™‹â€â™€ï¸ Author 
Shreya Mohan  
GitHub: @shreyaa-mohan
